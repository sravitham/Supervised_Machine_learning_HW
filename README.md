# Supervised_Machine_learning_HW

## Background:
##### Random Forest handles non-lienarities in data rather than the simple and linear behaviour of Logistic regression. Logistic Regression is a classification algorithm used to predict a discrete set of classes or categories (e.g., Yes/No, Young/Old, Happy/Sad); it returns a probability value of 0 or 1. In contrast, Random Forest Regression algorithm will sample the data and build several smaller, simpler decisions trees (i.e., a forest of trees), which are then combined to form a “strong classifier.”.

## Prediction
##### I predict that Random Forest Regression algorithm will be a more appropriate and accurate algorithm for this dataset. Due to the large size of the dataset, I don't think it would be appropriate to make a conclusion from one complex decision tree. Instead, Random Forest algorithm will form multiple small descision trees which will be combined to provide a 'strong classifier.

## Analysis:
##### Logistic Regression score resulted in 0.9919177328380795 versus Random Forest Score resulting in 0.9971798046498831. As predicted Random Forest algorithm provided a slightly higher score than Logistic Regression.  
